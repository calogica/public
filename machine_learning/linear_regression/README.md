The following are three different implementations of Linear Regression to demonstrate basic principles such as Gradient Descent, mini-batching in both numpy and Tensorflow.

Much credit goes to Sebastian Raschka, Aymeric Damien and Michelle Fullwood for their code, blogposts and presentations:

- Sebastian Raschka "Single-Layer Neural Networks and Gradient Descent" https://sebastianraschka.com/Articles/2015_singlelayer_neurons.html#gradient-descent
- Aymeric Damien Linear Regression in Tensorflow example: https://github.com/aymericdamien/TensorFlow-Examples/blob/master/notebooks/2_BasicModels/linear_regression.ipynb
- Michelle Fullwood "A gentle introduction to deep learning with TensorFlow" at PyCon 2017
https://www.youtube.com/watch?v=5e0TbyCkbCY&list=WL&index=5
https://github.com/michelleful/PyCon2017/blob/master/notebooks/Sample%20TensorFlow%20code.ipynb